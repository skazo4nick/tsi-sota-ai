# Configuration for the SLR Analytics Application

# --- Data Paths ---
# Paths are relative to the project root directory.
data_paths:
  raw_data_dir: "data/slr_raw/"          # For raw data from APIs
  processed_data_dir: "data/slr_processed/" # For cleaned and structured data
  analysis_output_dir: "data/slr_analysis/" # For keyword lists, embeddings, cluster assignments
  reports_output_dir: "output/slr_reports/" # For plots and final reports/tables
  # Add specific filenames if they are constant, otherwise they can be generated dynamically.
  processed_articles_file: "slr_processed_articles.csv"
  # Example: embedding_model_path: "models/bge-m3" # If hosting model locally

# --- Default Search Parameters ---
# These can be overridden by parameters passed to functions or CLI arguments.
default_search_params:
  start_year: 2020
  end_year: 2024 # Update as needed
  max_results_per_source: 100 # Default for comprehensive runs, can be set lower for testing
  # Default query - can be general or overridden.
  # query: "agentic AI in Supply Chain Management OR LLM logistics"

# --- API Client Settings ---
# API keys should primarily be managed via .env file.
# These settings are for non-sensitive parameters or if an API needs specific base URLs not hardcoded.
api_settings:
  CORE:
    # base_url: "https://api.core.ac.uk/v3/" # Already in client, but could be here
    # any_other_core_specific_setting: value
  arXiv:
    # base_url: "http://export.arxiv.org/api/" # Already in client
    # default_sort_by: "submittedDate"
  OpenAlex:
    # base_url: "https://api.openalex.org/" # Already in client
    # polite_pool_email: "your_registered_email@example.com" # Also in .env for api_clients.py, good to keep consistent if specified here too.
  semantic_scholar:
    # base_url: "https://api.semanticscholar.org/graph/v1/" # Already in client
    # recommendations_url: "https://api.semanticscholar.org/recommendations/v1/" # Already in client
    # user_agent: "tsi-sota-ai/1.0 (research@example.com)" # Update with your contact info

# --- NLP & Keyword Analysis Settings ---
keyword_analysis:
  # For NLP-based keyword extraction (e.g., TF-IDF, RAKE, YAKE!)
  nlp:
    methods: ['tfidf', 'rake', 'yake']
    tfidf:
      ngram_range: [1, 3]
      max_features: 1000
      min_df: 2
      max_df: 0.85
      stop_words: "english"
    rake:
      min_length: 1
      max_length: 4
      stopwords_file: null  # Use default English stopwords
    yake:
      language: "en"
      max_ngram_size: 3
      deduplication_threshold: 0.7
      num_keywords: 20
  
  # Output settings
  output:
    top_n_keywords: 20
    export_formats: ['csv', 'json']
    save_raw_extractions: true

# --- Semantic Embedding & Clustering Settings ---
semantic_analysis:
  # Embedding model configuration
  embedding:
    model_name: "BAAI/bge-m3"
    cache_dir: "./data/embeddings_cache"
    batch_size: 32
    device: "cpu"  # or "cuda" if GPU available
    max_length: 512  # Maximum sequence length
  
  # Clustering algorithms
  clustering:
    methods: ['kmeans', 'dbscan']
    kmeans:
      n_clusters: 10
      random_state: 42
      init: 'k-means++'
      max_iter: 300
    dbscan:
      eps: 0.5
      min_samples: 5
      metric: 'cosine'
  
  # Dimensionality reduction for visualization
  dimensionality_reduction:
    umap:
      n_neighbors: 15
      min_dist: 0.1
      n_components: 2
      metric: "cosine"
      random_state: 42
    pca:
      n_components: 2
      random_state: 42

# --- Visualization Settings ---
visualization:
  output_dir: "./data/visualizations"
  formats: ['png', 'svg']
  dpi: 300
  figsize: [12, 8]
  style: "whitegrid"  # seaborn style
  color_palette: "husl"

# --- Test Queries for Development ---
test_search_queries:
  limited_scope:
    - "LangGraph supply chain"
    - "YAKE keyword extraction SCM"
    - "BGE-M3 embeddings logistics"
  development:
    - "agentic AI SCM"
    - "LLM logistics"
  timeframe:
    start: "2023-01-01"
    end: "2024-12-31"

# --- Logging Configuration (Basic) ---
# For more advanced logging, a logging.conf file might be better.
logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL
  # log_file: "logs/slr_app.log" # If file logging is desired
