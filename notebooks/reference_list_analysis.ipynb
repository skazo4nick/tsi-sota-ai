{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference List Analysis\n",
    "\n",
    "This notebook analyzes all the articles references extracted from the CSV files located in the `data/references` folder. We will load all CSV files, combine them into a single DataFrame, and produce summary statistics such as:\n",
    "\n",
    "- Total number of articles\n",
    "- Distribution by publication year\n",
    "- List of unique journals\n",
    "- Additional descriptive statistics\n",
    "\n",
    "This analysis will help us quickly get an overview of the articles we plan to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bee86-06d3-4fdb-9d21-887ea8acb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the references folder\n",
    "references_dir = os.path.join('data', 'references')\n",
    "\n",
    "# Create a glob pattern to match all CSV files in the references directory\n",
    "csv_pattern = os.path.join(references_dir, '*.csv')\n",
    "csv_files = glob.glob(csv_pattern)\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in the directory: {references_dir}\")\n",
    "\n",
    "# Load each CSV file into a DataFrame and store in a list\n",
    "data_frames = []\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        data_frames.append(df)\n",
    "        print(f\"Loaded {csv_file} with shape {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_file}: {e}\")\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "references_df = pd.concat(data_frames, ignore_index=True)\n",
    "print(f\"Combined references data shape: {references_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Below are the first few rows of the combined references DataFrame to inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3132d60-3606-4b9b-9a34-532201707d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b08bdb-a09a-4873-8d76-c3a0273bf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of articles\n",
    "total_articles = references_df.shape[0]\n",
    "print(f\"Total number of articles: {total_articles}\")\n",
    "\n",
    "# Distribution by publication year (assuming 'year' column exists)\n",
    "if 'year' in references_df.columns:\n",
    "    year_distribution = references_df['year'].value_counts().sort_index()\n",
    "    print(\"\\nPublication Year Distribution:\")\n",
    "    print(year_distribution)\n",
    "else:\n",
    "    print(\"The column 'year' is not found in the data.\")\n",
    "\n",
    "# List of unique journals (assuming 'journal' column exists)\n",
    "if 'journal' in references_df.columns:\n",
    "    unique_journals = references_df['journal'].unique()\n",
    "    print(f\"\\nUnique journals ({len(unique_journals)}):\")\n",
    "    print(unique_journals)\n",
    "else:\n",
    "    print(\"The column 'journal' is not found in the data.\")\n",
    "\n",
    "# Publisher distribution if 'publisher' column exists\n",
    "if 'publisher' in references_df.columns:\n",
    "    publisher_distribution = references_df['publisher'].value_counts()\n",
    "    print(\"\\nPublisher Distribution (top 10):\")\n",
    "    print(publisher_distribution.head(10))\n",
    "else:\n",
    "    print(\"The column 'publisher' is not found in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOI Analysis and Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234abcd-5678-4abc-def0-123456789abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing DOIs\n",
    "missing_dois = references_df['doi'].isna().sum()\n",
    "print(f\"Number of entries with missing DOIs: {missing_dois}\")\n",
    "\n",
    "# Check DOI patterns\n",
    "if not missing_dois == len(references_df):\n",
    "    print(\"\\nSample of DOI patterns:\")\n",
    "    print(references_df['doi'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Analysis\n",
    "\n",
    "Analyzing abstracts can help us understand the content distribution and identify potential data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b384c-5c88-49b6-9afa-d2a9140a9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'abstract' in references_df.columns:\n",
    "    # Calculate abstract lengths\n",
    "    references_df['abstract_length'] = references_df['abstract'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"Abstract Statistics:\")\n",
    "    print(f\"Mean length: {references_df['abstract_length'].mean():.2f} characters\")\n",
    "    print(f\"Median length: {references_df['abstract_length'].median():.0f} characters\")\n",
    "    print(f\"Shortest abstract: {references_df['abstract_length'].min()} characters\")\n",
    "    print(f\"Longest abstract: {references_df['abstract_length'].max()} characters\")\n",
    "    \n",
    "    # Check for missing abstracts\n",
    "    missing_abstracts = references_df['abstract'].isna().sum()\n",
    "    print(f\"\\nNumber of entries with missing abstracts: {missing_abstracts}\")\n",
    "else:\n",
    "    print(\"The column 'abstract' is not found in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data\n",
    "\n",
    "Save the processed DataFrame for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-data-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON for easier reading\n",
    "output_json = os.path.join('data', 'references_analysis.json')\n",
    "references_df.to_json(output_json, orient='records', indent=2)\n",
    "print(f\"Saved processed data to: {output_json}\")\n",
    "\n",
    "# Save basic statistics to a separate file\n",
    "stats_dict = {\n",
    "    'total_articles': total_articles,\n",
    "    'unique_journals': len(references_df['journal'].unique()) if 'journal' in references_df.columns else 0,\n",
    "    'year_range': f\"{references_df['year'].min()}-{references_df['year'].max()}\" if 'year' in references_df.columns else 'N/A',\n",
    "    'missing_dois': missing_dois if 'doi' in references_df.columns else 'N/A',\n",
    "    'missing_abstracts': missing_abstracts if 'abstract' in references_df.columns else 'N/A'\n",
    "}\n",
    "\n",
    "stats_json = os.path.join('data', 'references_stats.json')\n",
    "with open(stats_json, 'w') as f:\n",
    "    json.dump(stats_dict, f, indent=2)\n",
    "print(f\"Saved statistics to: {stats_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
