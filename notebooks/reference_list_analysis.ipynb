{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference List Analysis\n",
    "\n",
    "This notebook analyzes all the articles references from our CSV files located in the `data/references` folder. We load the files, combine them into a single DataFrame, and produce summary statistics such as:\n",
    "\n",
    "- Total number of articles\n",
    "- Distribution by publication year\n",
    "- List of unique journals\n",
    "- Additional descriptive statistics\n",
    "\n",
    "This analysis will help us quickly get an overview of the articles we plan to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: /workspaces/tsi-sota-ai/data/references\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust path to be relative to the repository root\n",
    "# Going up one directory from notebooks/ to reach the project root\n",
    "references_dir = os.path.join('..', 'data', 'references')\n",
    "\n",
    "# Print absolute path to help debug\n",
    "print(f\"Looking for files in: {os.path.abspath(references_dir)}\")\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(references_dir):\n",
    "    print(f\"Directory does not exist: {references_dir}\")\n",
    "    # Create if needed\n",
    "    # os.makedirs(references_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: /workspaces/tsi-sota-ai/data/references\n",
      "Loaded 1.2.2.1 LR - The Specialist Shortage and its Impact.csv into 1_specialists_df with shape (94, 12)\n",
      "Loaded 1.2.2.2 LR - AI Applications in SCM Decision Support.csv into 2_aiscm_df with shape (69, 12)\n",
      "Loaded 1.2.2.3 LR - Human-AI Collaboration in SCM.csv into 3_humanai_df with shape (97, 12)\n",
      "Loaded 1.2.2.4 LR - Challenges and Limitations of LLMs in SCM.csv into 4_challenges_df with shape (54, 12)\n",
      "Loaded 1.2.2.5 LR - Decision-Making Processes.csv into 5_decision_df with shape (110, 12)\n",
      "Loaded 1.2.2.6 LR - Agents.csv into 6_agents_df with shape (169, 12)\n",
      "\n",
      "1_specialists_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94 entries, 0 to 93\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           94 non-null     object \n",
      " 1   title          94 non-null     object \n",
      " 2   doi            94 non-null     object \n",
      " 3   authors        94 non-null     object \n",
      " 4   journal        94 non-null     object \n",
      " 5   short_journal  87 non-null     object \n",
      " 6   volume         94 non-null     int64  \n",
      " 7   year           94 non-null     int64  \n",
      " 8   publisher      94 non-null     object \n",
      " 9   issue          84 non-null     float64\n",
      " 10  page           88 non-null     object \n",
      " 11  abstract       93 non-null     object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 8.9+ KB\n",
      "None\n",
      "\n",
      "2_aiscm_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           69 non-null     object \n",
      " 1   title          69 non-null     object \n",
      " 2   doi            69 non-null     object \n",
      " 3   authors        69 non-null     object \n",
      " 4   journal        69 non-null     object \n",
      " 5   short_journal  68 non-null     object \n",
      " 6   volume         68 non-null     float64\n",
      " 7   year           69 non-null     int64  \n",
      " 8   publisher      69 non-null     object \n",
      " 9   issue          58 non-null     float64\n",
      " 10  page           54 non-null     object \n",
      " 11  abstract       69 non-null     object \n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 6.6+ KB\n",
      "None\n",
      "\n",
      "3_humanai_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           97 non-null     object \n",
      " 1   title          97 non-null     object \n",
      " 2   doi            97 non-null     object \n",
      " 3   authors        97 non-null     object \n",
      " 4   journal        97 non-null     object \n",
      " 5   short_journal  97 non-null     object \n",
      " 6   volume         97 non-null     int64  \n",
      " 7   year           97 non-null     int64  \n",
      " 8   publisher      97 non-null     object \n",
      " 9   issue          42 non-null     float64\n",
      " 10  page           44 non-null     object \n",
      " 11  abstract       96 non-null     object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 9.2+ KB\n",
      "None\n",
      "\n",
      "4_challenges_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           54 non-null     object \n",
      " 1   title          54 non-null     object \n",
      " 2   doi            54 non-null     object \n",
      " 3   authors        54 non-null     object \n",
      " 4   journal        54 non-null     object \n",
      " 5   short_journal  51 non-null     object \n",
      " 6   volume         54 non-null     int64  \n",
      " 7   year           54 non-null     int64  \n",
      " 8   publisher      54 non-null     object \n",
      " 9   issue          36 non-null     float64\n",
      " 10  page           37 non-null     object \n",
      " 11  abstract       54 non-null     object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "\n",
      "5_decision_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           110 non-null    object \n",
      " 1   title          110 non-null    object \n",
      " 2   doi            110 non-null    object \n",
      " 3   authors        110 non-null    object \n",
      " 4   journal        110 non-null    object \n",
      " 5   short_journal  105 non-null    object \n",
      " 6   volume         109 non-null    float64\n",
      " 7   year           110 non-null    int64  \n",
      " 8   publisher      110 non-null    object \n",
      " 9   issue          78 non-null     float64\n",
      " 10  page           75 non-null     object \n",
      " 11  abstract       108 non-null    object \n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 10.4+ KB\n",
      "None\n",
      "\n",
      "6_agents_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169 entries, 0 to 168\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           169 non-null    object \n",
      " 1   title          169 non-null    object \n",
      " 2   doi            169 non-null    object \n",
      " 3   authors        169 non-null    object \n",
      " 4   journal        169 non-null    object \n",
      " 5   short_journal  155 non-null    object \n",
      " 6   volume         167 non-null    float64\n",
      " 7   year           169 non-null    int64  \n",
      " 8   publisher      169 non-null    object \n",
      " 9   issue          105 non-null    float64\n",
      " 10  page           117 non-null    object \n",
      " 11  abstract       167 non-null    object \n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 16.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Use absolute path or proper relative path\n",
    "# Option 1: Absolute path\n",
    "references_dir = '/workspaces/tsi-sota-ai/data/references'\n",
    "\n",
    "# Option 2: Relative path (going up one directory from notebooks)\n",
    "# references_dir = os.path.join('..', 'data', 'references')\n",
    "\n",
    "print(f\"Looking for files in: {references_dir}\")\n",
    "\n",
    "# Dictionary with exact filenames and their corresponding DataFrame names\n",
    "file_mapping = {\n",
    "    '1.2.2.1 LR - The Specialist Shortage and its Impact.csv': '1_specialists_df',\n",
    "    '1.2.2.2 LR - AI Applications in SCM Decision Support.csv': '2_aiscm_df',\n",
    "    '1.2.2.3 LR - Human-AI Collaboration in SCM.csv': '3_humanai_df',\n",
    "    '1.2.2.4 LR - Challenges and Limitations of LLMs in SCM.csv': '4_challenges_df',\n",
    "    '1.2.2.5 LR - Decision-Making Processes.csv': '5_decision_df',\n",
    "    '1.2.2.6 LR - Agents.csv': '6_agents_df'\n",
    "}\n",
    "\n",
    "# Initialize dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file\n",
    "for filename, df_name in file_mapping.items():\n",
    "    file_path = os.path.join(references_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes[df_name] = df\n",
    "        print(f\"Loaded {filename} into {df_name} with shape {df.shape}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Assign DataFrames to individual variables\n",
    "locals().update(dataframes)\n",
    "\n",
    "# Print basic info about each DataFrame\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n{name} info:\")\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine DataFrames\n",
    "\n",
    "Combine all individual DataFrames into one for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined references data shape: (593, 12)\n"
     ]
    }
   ],
   "source": [
    "# Combine all DataFrames into one\n",
    "references_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "print(f\"Combined references data shape: {references_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Below are the first few rows of the combined references DataFrame to inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>short_journal</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>issue</th>\n",
       "      <th>page</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-13</td>\n",
       "      <td>Transformative Procurement Trends: Integrating...</td>\n",
       "      <td>10.3390/logistics7030063</td>\n",
       "      <td>[{'author_name': 'Areej Althabatah', 'author_s...</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>MDPI AG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63</td>\n",
       "      <td>Background: the advent of Industry 4.0 (I4.0) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>Exploring Progress with Supply Chain Risk Mana...</td>\n",
       "      <td>10.3390/logistics5040070</td>\n",
       "      <td>[{'author_name': 'Remko van Hoek', 'author_slu...</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>MDPI AG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>Background: In response to calls for actionabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Exploring Applications and Practical Examples ...</td>\n",
       "      <td>10.3390/logistics7040091</td>\n",
       "      <td>[{'author_name': 'João Reis', 'author_slug': '...</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>MDPI AG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>91</td>\n",
       "      <td>Background: Material Requirements Planning (MR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Sustainable Innovations in the Food Industry t...</td>\n",
       "      <td>10.3390/logistics5040066</td>\n",
       "      <td>[{'author_name': 'Saurabh Sharma', 'author_slu...</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>MDPI AG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66</td>\n",
       "      <td>The agri-food sector is an endless source of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>Artificial Intelligence (AI): Multidisciplinar...</td>\n",
       "      <td>10.1016/j.ijinfomgt.2019.08.002</td>\n",
       "      <td>[{'author_name': 'Yogesh K. Dwivedi', 'author_...</td>\n",
       "      <td>International Journal of Information Management</td>\n",
       "      <td>International Journal of Information Management</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>Elsevier BV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101994</td>\n",
       "      <td>As far back as the industrial revolution, sign...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2023-09-13  Transformative Procurement Trends: Integrating...   \n",
       "1  2021-10-07  Exploring Progress with Supply Chain Risk Mana...   \n",
       "2  2023-12-01  Exploring Applications and Practical Examples ...   \n",
       "3  2021-09-27  Sustainable Innovations in the Food Industry t...   \n",
       "4  2021-04-01  Artificial Intelligence (AI): Multidisciplinar...   \n",
       "\n",
       "                               doi  \\\n",
       "0         10.3390/logistics7030063   \n",
       "1         10.3390/logistics5040070   \n",
       "2         10.3390/logistics7040091   \n",
       "3         10.3390/logistics5040066   \n",
       "4  10.1016/j.ijinfomgt.2019.08.002   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'author_name': 'Areej Althabatah', 'author_s...   \n",
       "1  [{'author_name': 'Remko van Hoek', 'author_slu...   \n",
       "2  [{'author_name': 'João Reis', 'author_slug': '...   \n",
       "3  [{'author_name': 'Saurabh Sharma', 'author_slu...   \n",
       "4  [{'author_name': 'Yogesh K. Dwivedi', 'author_...   \n",
       "\n",
       "                                           journal  \\\n",
       "0                                        Logistics   \n",
       "1                                        Logistics   \n",
       "2                                        Logistics   \n",
       "3                                        Logistics   \n",
       "4  International Journal of Information Management   \n",
       "\n",
       "                                     short_journal  volume  year    publisher  \\\n",
       "0                                        Logistics     7.0  2023      MDPI AG   \n",
       "1                                        Logistics     5.0  2021      MDPI AG   \n",
       "2                                        Logistics     7.0  2023      MDPI AG   \n",
       "3                                        Logistics     5.0  2021      MDPI AG   \n",
       "4  International Journal of Information Management    57.0  2021  Elsevier BV   \n",
       "\n",
       "   issue    page                                           abstract  \n",
       "0    3.0      63  Background: the advent of Industry 4.0 (I4.0) ...  \n",
       "1    4.0      70  Background: In response to calls for actionabl...  \n",
       "2    4.0      91  Background: Material Requirements Planning (MR...  \n",
       "3    4.0      66  The agri-food sector is an endless source of e...  \n",
       "4    NaN  101994  As far back as the industrial revolution, sign...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles: 593\n",
      "\n",
      "Publication Year Distribution:\n",
      "year\n",
      "2008      1\n",
      "2010      3\n",
      "2011      2\n",
      "2012      1\n",
      "2013      4\n",
      "2014      5\n",
      "2015      2\n",
      "2016      3\n",
      "2017      6\n",
      "2018     24\n",
      "2019     22\n",
      "2020     58\n",
      "2021    113\n",
      "2022    121\n",
      "2023    182\n",
      "2024     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique journals (23):\n",
      "['Logistics' 'International Journal of Information Management'\n",
      " 'Transport and Telecommunication Journal'\n",
      " 'International Journal of Information Systems and Project Management'\n",
      " 'Applied System Innovation' 'Sustainable Operations and Computers'\n",
      " 'Smart Cities' 'Management Science' 'Big Data and Cognitive Computing'\n",
      " 'Iet Collaborative Intelligent Manufacturing'\n",
      " 'Frontiers in Artificial Intelligence' 'Science'\n",
      " 'Frontiers in Robotics and Ai' 'Journal of Big Data'\n",
      " 'Machine Learning and Knowledge Extraction'\n",
      " 'Journal of Artificial Intelligence Research'\n",
      " 'Nature Machine Intelligence'\n",
      " 'Transportation Research Interdisciplinary Perspectives'\n",
      " 'Transactions of the Association for Computational Linguistics'\n",
      " 'Journal of Artificial Intelligence and Soft Computing Research'\n",
      " 'Network Neuroscience' 'Neuromorphic Computing and Engineering'\n",
      " 'Caai Transactions on Intelligence Technology']\n",
      "\n",
      "Publisher Distribution (top 10):\n",
      "publisher\n",
      "MDPI AG                                                                    278\n",
      "Frontiers Media SA                                                         154\n",
      "Institute for Operations Research and the Management Sciences (INFORMS)     32\n",
      "Springer Science and Business Media LLC                                     27\n",
      "Walter de Gruyter GmbH                                                      25\n",
      "University of Minho                                                         24\n",
      "AI Access Foundation                                                        22\n",
      "Institution of Engineering and Technology (IET)                             17\n",
      "Elsevier BV                                                                  7\n",
      "MIT Press                                                                    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total number of articles\n",
    "total_articles = references_df.shape[0]\n",
    "print(f\"Total number of articles: {total_articles}\")\n",
    "\n",
    "# Distribution by publication year (assuming 'year' column exists)\n",
    "if 'year' in references_df.columns:\n",
    "    year_distribution = references_df['year'].value_counts().sort_index()\n",
    "    print(\"\\nPublication Year Distribution:\")\n",
    "    print(year_distribution)\n",
    "else:\n",
    "    print(\"The column 'year' is not found in the data.\")\n",
    "\n",
    "# List of unique journals (assuming 'journal' column exists)\n",
    "if 'journal' in references_df.columns:\n",
    "    unique_journals = references_df['journal'].unique()\n",
    "    print(f\"\\nUnique journals ({len(unique_journals)}):\")\n",
    "    print(unique_journals)\n",
    "else:\n",
    "    print(\"The column 'journal' is not found in the data.\")\n",
    "\n",
    "# Publisher distribution if 'publisher' column exists\n",
    "if 'publisher' in references_df.columns:\n",
    "    publisher_distribution = references_df['publisher'].value_counts()\n",
    "    print(\"\\nPublisher Distribution (top 10):\")\n",
    "    print(publisher_distribution.head(10))\n",
    "else:\n",
    "    print(\"The column 'publisher' is not found in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOI Analysis and Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with missing DOIs: 0\n",
      "\n",
      "Sample of DOI patterns:\n",
      "doi\n",
      "10.3390/logistics7030063      15\n",
      "10.3390/logistics6030048      11\n",
      "10.1186/s40537-020-00329-2     9\n",
      "10.3390/logistics7010001       7\n",
      "10.3389/frai.2023.1264372      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing DOIs\n",
    "missing_dois = references_df['doi'].isna().sum()\n",
    "print(f\"Number of entries with missing DOIs: {missing_dois}\")\n",
    "\n",
    "# Check DOI patterns\n",
    "if not missing_dois == len(references_df):\n",
    "    print(\"\\nSample of DOI patterns:\")\n",
    "    print(references_df['doi'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Analysis\n",
    "\n",
    "Analyzing abstracts can help us understand the content distribution and identify potential data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Statistics:\n",
      "Mean length: 1437.88 characters\n",
      "Median length: 1396 characters\n",
      "Shortest abstract: 0 characters\n",
      "Longest abstract: 3071 characters\n",
      "\n",
      "Number of entries with missing abstracts: 6\n"
     ]
    }
   ],
   "source": [
    "if 'abstract' in references_df.columns:\n",
    "    # Calculate abstract lengths\n",
    "    references_df['abstract_length'] = references_df['abstract'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"Abstract Statistics:\")\n",
    "    print(f\"Mean length: {references_df['abstract_length'].mean():.2f} characters\")\n",
    "    print(f\"Median length: {references_df['abstract_length'].median():.0f} characters\")\n",
    "    print(f\"Shortest abstract: {references_df['abstract_length'].min()} characters\")\n",
    "    print(f\"Longest abstract: {references_df['abstract_length'].max()} characters\")\n",
    "    \n",
    "    # Check for missing abstracts\n",
    "    missing_abstracts = references_df['abstract'].isna().sum()\n",
    "    print(f\"\\nNumber of entries with missing abstracts: {missing_abstracts}\")\n",
    "else:\n",
    "    print(\"The column 'abstract' is not found in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data\n",
    "\n",
    "Save the processed DataFrame for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save to JSON for easier reading\u001b[39;00m\n\u001b[1;32m      2\u001b[0m output_json \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences_analysis.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mreferences_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved processed data to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save basic statistics to a separate file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tsi/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tsi/lib/python3.11/site-packages/pandas/core/generic.py:2702\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m   2699\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2700\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tsi/lib/python3.11/site-packages/pandas/io/json/_json.py:217\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m     s \u001b[38;5;241m=\u001b[39m convert_to_line_delimits(s)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    220\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tsi/lib/python3.11/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tsi/lib/python3.11/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "# Create proper paths relative to project root\n",
    "# Option 1: Using absolute path\n",
    "data_dir = '/workspaces/tsi-sota-ai/data'\n",
    "\n",
    "# Option 2: Using relative path\n",
    "# data_dir = os.path.join('..', 'data')  # Go up one level from notebooks/\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"Using data directory: {data_dir}\")\n",
    "\n",
    "# Save to JSON using the correct path\n",
    "output_json = os.path.join(data_dir, 'references_analysis.json')\n",
    "references_df.to_json(output_json, orient='records', indent=2)\n",
    "print(f\"Saved processed data to: {output_json}\")\n",
    "\n",
    "# Save basic statistics to a separate file\n",
    "stats_dict = {\n",
    "    'total_articles': total_articles,\n",
    "    'unique_journals': len(references_df['journal'].unique()) if 'journal' in references_df.columns else 0,\n",
    "    'year_range': f\"{references_df['year'].min()}-{references_df['year'].max()}\" if 'year' in references_df.columns else 'N/A',\n",
    "    'missing_dois': missing_dois if 'doi' in references_df.columns else 'N/A',\n",
    "    'missing_abstracts': missing_abstracts if 'abstract' in references_df.columns else 'N/A'\n",
    "}\n",
    "\n",
    "stats_json = os.path.join(data_dir, 'references_stats.json')\n",
    "with open(stats_json, 'w') as f:\n",
    "    json.dump(stats_dict, f, indent=2)\n",
    "print(f\"Saved statistics to: {stats_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
